{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "501e2944",
   "metadata": {},
   "source": [
    "# QC Checklist Script for credits -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fa090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "# Define your quality check functions here\n",
    "def check_null_values(df):\n",
    "    null_columns = df.columns[df.isnull().any()].tolist()\n",
    "    if len(null_columns) > 0:\n",
    "        return 'FAILED', f'Columns {null_columns} contain null values'\n",
    "    else:\n",
    "        return 'PASSED', ''\n",
    "    \n",
    "def check_unique_values(df, column):\n",
    "    if df[column].nunique() == len(df[column]):\n",
    "        return 'PASSED', ''\n",
    "    else:\n",
    "        return 'FAILED', f'Column {column} contains duplicate values'\n",
    "    \n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Read in your data from S3\n",
    "bucket_name = 'capstone-harsh'\n",
    "input_file_key = 's3://capstone-harsh/amazon prime/credits.csv'\n",
    "obj = s3.get_object(Bucket='capstone-harsh', Key='amazon prime/credits.csv')\n",
    "df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "results = []\n",
    "\n",
    "# Check for null values in all columns\n",
    "result, message = check_null_values(df)\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the person_id column\n",
    "result, message = check_unique_values(df, 'person_id')\n",
    "results.append(('Check for unique values in person_id column', result, message))\n",
    "\n",
    "# Check for unique values in the id column\n",
    "result, message = check_unique_values(df, 'id')\n",
    "results.append(('Check for unique values in id column', result, message))\n",
    "\n",
    "# Check for unique values in the name column\n",
    "result, message = check_unique_values(df, 'name')\n",
    "results.append(('Check for unique values in name column', result, message))\n",
    "\n",
    "# Check for unique values in the character column\n",
    "result, message = check_unique_values(df, 'character')\n",
    "results.append(('Check for unique values in character column', result, message))\n",
    "\n",
    "# Check for unique values in the role column\n",
    "result, message = check_unique_values(df, 'role')\n",
    "results.append(('Check for unique values in role column', result, message))\n",
    "\n",
    "# Save results to a CSV file in S3\n",
    "output_file_key = 'qc-results/qc_final.csv'\n",
    "qc_results = pd.DataFrame(results, columns=['Check Description', 'Result', 'Message'])\n",
    "csv_buffer = qc_results.to_csv(index=False).encode('utf-8')\n",
    "s3.put_object(Bucket='capstone-harsh', Key='qc-results/qc_final.csv', Body=csv_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69260659",
   "metadata": {},
   "source": [
    "# QC Checklist Script for titles -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "# Define your quality check functions here\n",
    "def check_null_values(df, column):\n",
    "    null_columns = df.columns[df.isnull().any()].tolist()\n",
    "    if len(null_columns) > 0:\n",
    "        return 'FAILED', f'Columns {column} contain null values'\n",
    "    else:\n",
    "        return 'PASSED', ''\n",
    "\n",
    "def check_unique_values(df, column):\n",
    "    if df[column].nunique() == len(df[column]):\n",
    "        return 'PASSED', ''\n",
    "    else:\n",
    "        return 'FAILED', f'Column {column} contains duplicate values'\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Read in your data from S3\n",
    "bucket_name = 'capstone-harsh'\n",
    "input_file_key = 's3://capstone-harsh/amazon prime/titles.csv'\n",
    "obj = s3.get_object(Bucket='capstone-harsh', Key='amazon prime/titles.csv')\n",
    "df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "results = []\n",
    "\n",
    "# Check for null values in id column\n",
    "result, message = check_null_values(df,'id')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the id column\n",
    "result, message = check_unique_values(df, 'id')\n",
    "results.append(('Check for unique values in id column', result, message))\n",
    "\n",
    "# Check for null values in title column\n",
    "result, message = check_null_values(df,'title')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the title column\n",
    "result, message = check_unique_values(df, 'title')\n",
    "results.append(('Check for unique values in title column', result, message))\n",
    "\n",
    "# Check for null values in type column\n",
    "result, message = check_null_values(df,'type')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the type column\n",
    "result, message = check_unique_values(df, 'type')\n",
    "results.append(('Check for unique values in type column', result, message))\n",
    "\n",
    "# Check for null values in description column\n",
    "result, message = check_null_values(df,'description')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the description column\n",
    "result, message = check_unique_values(df, 'description')\n",
    "results.append(('Check for unique values in description column', result, message))\n",
    "\n",
    "# Check for null values in release_year column\n",
    "result, message = check_null_values(df,'release_year')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the release_year column\n",
    "result, message = check_unique_values(df, 'release_year')\n",
    "results.append(('Check for unique values in release_year column', result, message))\n",
    "\n",
    "# Check for null values in age_certification column\n",
    "result, message = check_null_values(df,'age_certification')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the age_certification column\n",
    "result, message = check_unique_values(df, 'age_certification')\n",
    "results.append(('Check for unique values in age_certification column', result, message))\n",
    "\n",
    "# Check for null values in runtime column\n",
    "result, message = check_null_values(df,'runtime')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the runtime column\n",
    "result, message = check_unique_values(df, 'runtime')\n",
    "results.append(('Check for unique values in runtime column', result, message))\n",
    "\n",
    "# Check for null values in genres column\n",
    "result, message = check_null_values(df,'genres')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the genres column\n",
    "result, message = check_unique_values(df, 'genres')\n",
    "results.append(('Check for unique values in genres column', result, message))\n",
    "\n",
    "# Check for null values in production_countries column\n",
    "result, message = check_null_values(df,'production_countries')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the production_countries column\n",
    "result, message = check_unique_values(df, 'production_countries')\n",
    "results.append(('Check for unique values in production_countries column', result, message))\n",
    "\n",
    "# Check for null values in seasons column\n",
    "result, message = check_null_values(df,'seasons')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the seasons column\n",
    "result, message = check_unique_values(df, 'seasons')\n",
    "results.append(('Check for unique values in seasons column', result, message))\n",
    "\n",
    "# Check for null values in imdb_id column\n",
    "result, message = check_null_values(df,'imdb_id')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the imdb_id column\n",
    "result, message = check_unique_values(df, 'imdb_id')\n",
    "results.append(('Check for unique values in imdb_id column', result, message))\n",
    "\n",
    "# Check for null values in imdb_score column\n",
    "result, message = check_null_values(df,'imdb_score')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the imdb_score column\n",
    "result, message = check_unique_values(df, 'imdb_score')\n",
    "results.append(('Check for unique values in imdb_score column', result, message))\n",
    "\n",
    "# Check for null values in imdb_votes column\n",
    "result, message = check_null_values(df,'imdb_votes')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the imdb_votes column\n",
    "result, message = check_unique_values(df, 'imdb_votes')\n",
    "results.append(('Check for unique values in imdb_votes column', result, message))\n",
    "\n",
    "# Check for null values in tmdb_popularity column\n",
    "result, message = check_null_values(df,'tmdb_popularity')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the tmdb_popularity column\n",
    "result, message = check_unique_values(df, 'tmdb_popularity')\n",
    "results.append(('Check for unique values in tmdb_popularity column', result, message))\n",
    "\n",
    "# Check for null values in tmdb_score column\n",
    "result, message = check_null_values(df,'tmdb_score')\n",
    "results.append(('Check for null values', result, message))\n",
    "\n",
    "# Check for unique values in the tmdb_score column\n",
    "result, message = check_unique_values(df, 'tmdb_score')\n",
    "results.append(('Check for unique values in tmdb_score column', result, message))\n",
    "\n",
    "# Save results to a CSV file in S3\n",
    "output_file_key = 'qc-results/qc-results.csv'\n",
    "qc_results = pd.DataFrame(results, columns=['Check Description', 'Result', 'Message'])\n",
    "csv_buffer = qc_results.to_csv(index=False).encode('utf-8')\n",
    "s3.put_object(Bucket='capstone-harsh', Key='qc-results/qc-results.csv', Body=csv_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dae07f",
   "metadata": {},
   "source": [
    "# JSON code for custom made in-line policy -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "{ \n",
    "    \"Version\": \"2012-10-17\", \n",
    "    \"Statement\": [ \n",
    "        { \"Effect\": \"Allow\", \n",
    "        \"Action\": \"iam:PassRole\", \n",
    "        \"Resource\": \"arn:aws:iam::462586494477:role/qc-capstone\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bfccbe",
   "metadata": {},
   "source": [
    "# Data Clean + SNS Script -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import boto3\n",
    "from io import StringIO\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Create an SNS client\n",
    "sns = boto3.client('sns')\n",
    "\n",
    "# Set the SNS topic ARN\n",
    "topic_arn = 'arn:aws:sns:ap-south-1:462586494477:Data-Clean'\n",
    "\n",
    "try:\n",
    "    # Set the S3 file paths\n",
    "    input_bucket = 'capstone-harsh'\n",
    "    input_file_key = 's3://capstone-harsh/amazon prime/titles.csv'\n",
    "    output_bucket = 'capstone-harsh'\n",
    "    output_file_key = 's3://capstone-harsh/Cleaned_data_sns/qc-results.csv'\n",
    "    \n",
    "    # Read the CSV file from S3 into a DataFrame\n",
    "    csv_obj = s3.get_object(Bucket='capstone-harsh', Key='amazon prime/titles.csv')\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(csv_string))\n",
    "    df.fillna('unknown', inplace=True)\n",
    "    for col in df.columns:\n",
    "        # Remove leading and trailing punctuation\n",
    "        df[col] = df[col].apply(lambda x: re.sub(r'^\\W+|\\W+$', '', str(x)))\n",
    "        # Remove leading and trailing white space\n",
    "        df[col] = df[col].apply(lambda x: x.strip())\n",
    "        # Remove special characters and consecutive white spaces\n",
    "        df[col] = df[col].apply(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "        df[col] = df[col].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "        # Remove leading and trailing quotation marks\n",
    "        df[col] = df[col].apply(lambda x: re.sub(r'^\"|\"$', '', str(x)))\n",
    "    # Save the cleaned data to a new CSV file on S3\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    s3.put_object(Body=csv_buffer.getvalue(), Bucket='capstone-harsh', Key='Cleaned_data_sns/qc-results.csv')\n",
    "    # ...\n",
    "    # Job completed successfully\n",
    "    sns.publish(TopicArn='arn:aws:sns:ap-south-1:462586494477:Data-Clean', Subject='AWS Data-Clean Report', Message='The AWS Glue job ran successfully and the data is cleaned  is accomplished effectively.')\n",
    "except Exception as e:\n",
    "    # Handle the exception and publish a message to the SNS topic\n",
    "    sns.publish(TopicArn='arn:aws:sns:ap-south-1:462586494477:Data-Clean', Subject='AWS Data-Clean Report', Message=f\"The AWS Glue job failed with an error and the data is not cleaned: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec5d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
